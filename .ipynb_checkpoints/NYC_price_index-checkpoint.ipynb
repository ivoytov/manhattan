{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKahawVnsdCe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.dates import date2num, num2date\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tN6UJpoPsdC-"
   },
   "outputs": [],
   "source": [
    "cols = ['BOROUGH', 'NEIGHBORHOOD', 'BUILDING CLASS CATEGORY',\n",
    "       'TAX CLASS AT PRESENT', 'BLOCK', 'LOT', 'EASE-MENT',\n",
    "       'BUILDING CLASS AT PRESENT', 'ADDRESS', 'APARTMENT NUMBER', 'ZIP CODE',\n",
    "       'RESIDENTIAL UNITS', 'COMMERCIAL UNITS', 'TOTAL UNITS',\n",
    "       'LAND SQUARE FEET', 'GROSS SQUARE FEET', 'YEAR BUILT',\n",
    "       'TAX CLASS AT TIME OF SALE', 'BUILDING CLASS AT TIME OF SALE',\n",
    "       'SALE PRICE', 'SALE DATE']\n",
    "cols = [col.lower().replace(\" \",\"_\") for col in cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all real estate transaction data from [NYC.gov](https://www1.nyc.gov/site/finance/taxes/property-annualized-sales-update.page) for January 2003 to May 2020. Only closed transactions are included. Column names are the same in all files. Convert to lower case for easier use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "TebaJ6YdsdDL",
    "outputId": "318e3b23-4a0e-471c-b2c5-82f3326c0989"
   },
   "outputs": [],
   "source": [
    "# from https://www1.nyc.gov/site/finance/taxes/property-annualized-sales-update.page\n",
    "\n",
    "# ex: https://www1.nyc.gov/assets/finance/downloads/pdf/rolling_sales/annualized-sales/2019/2019_manhattan.xlsx\n",
    "url_prefix = 'https://www1.nyc.gov/assets/finance/downloads/pdf/rolling_sales'\n",
    "years = range(2010,2020)\n",
    "links = [f\"{url_prefix}/annualized-sales/{year}/{year}_manhattan.xls{'x' if year > 2017 else ''}\" for year in years ]\n",
    "links += [url_prefix + \"/rollingsales_manhattan.xls\", url_prefix + \"/annualized-sales/2009_manhattan.xls\",\n",
    "         \"https://www1.nyc.gov/assets/finance/downloads/pdf/09pdf/rolling_sales/sales_2008_manhattan.xls\", \n",
    "         \"https://www1.nyc.gov/assets/finance/downloads/excel/rolling_sales/sales_2007_manhattan.xls\",\n",
    "         *[f\"https://www1.nyc.gov/assets/finance/downloads/sales_manhattan_0{n}.xls\" for n in range(3,7)] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude any transaction with sale price under \\$100,000 as it might not be an arms length transaction or just bad data. The very last file we downloaded covers period of May 2019 - April 2020, so we need to remove duplicates in April 2019 - December 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 810
    },
    "colab_type": "code",
    "id": "NDF3IalDsdDt",
    "outputId": "9b433a1a-7f2d-41cc-8407-8f5b2e382db0"
   },
   "outputs": [],
   "source": [
    "dfs = [pd.read_excel(link, skiprows=4, names=cols, parse_dates=[20]) for link in links]\n",
    "df = pd.concat(dfs).drop_duplicates()\n",
    "df = df[(df.sale_price > 100000)]\n",
    "df = df[['neighborhood', 'block','lot', 'address', 'apartment_number', 'gross_square_feet', 'sale_price', 'year_built', 'sale_date']]\n",
    "df.neighborhood = df.neighborhood.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a unique ID for each unit by combining the block and unit numbers. We convert transaction periods to quarters (our index will be quarterly as a result). If the same house sold multiple times in the same quarter, remove the first transaction(s) and only keep the last transaction. This most likely represents a contractor flip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOihtJQ8sdEE"
   },
   "outputs": [],
   "source": [
    "df['uid'] = df.block.map(str) + '_' + df.lot.map(str)\n",
    "df['period'] = pd.PeriodIndex(df.sale_date, freq='Q')\n",
    "df = df.drop_duplicates(subset=['period','uid'],keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "IDIvrpf8sdEY",
    "outputId": "bb4ae57a-0e9e-4c3e-c1fb-9dc927ca865c"
   },
   "outputs": [],
   "source": [
    "''' Function takes in DataFrame rpt_sales with columns `uid`, `period`, and `sale_price`. \n",
    "    Returns:\n",
    "        design matrices X, W, and Z as specified in the Case Shiller index methodology\n",
    "        array deltaT:    number of periods elapsed between each sale pair\n",
    "        array uid_key:   for each row of matrices, which house it represents\n",
    "        array periods:   list of all unique periods, so columns can be converted to Periods \n",
    "'''\n",
    "def createDesignMatrices(rpt_sales):\n",
    "    grouped = rpt_sales.groupby('uid')\n",
    "    S = np.sum(grouped.size()-1)\n",
    "    periods = list(rpt_sales.period.unique())\n",
    "    T = len(periods)\n",
    "\n",
    "    # construct blank design matrices\n",
    "    X = np.zeros((S, T))\n",
    "    deltaT = np.zeros((S,1))\n",
    "    \n",
    "    uid_key = []\n",
    "    row = 0\n",
    "    for house, group in grouped:\n",
    "      for i in range(len(group)-1):\n",
    "        first = (group.iloc[i].sale_price, periods.index(group.iloc[i].period))\n",
    "        second = (group.iloc[i+1].sale_price, periods.index(group.iloc[i+1].period))\n",
    "\n",
    "        X[row,first[1]] = -first[0]\n",
    "        X[row,second[1]] = second[0]\n",
    "        deltaT[row] = second[1] - first[1]\n",
    "\n",
    "        uid_key.append(house)\n",
    "        row += 1\n",
    "\n",
    "    W = np.reshape(-X[:,0],(-1,1))\n",
    "    X = X[:,1:]\n",
    "    Z = np.sign(X)\n",
    "\n",
    "    return X, W, Z, deltaT, uid_key, periods\n",
    "\n",
    "'''\n",
    "    Constructs Case Shiller repeat sales index\n",
    "    inputs: X,Z,W - design matrices as specified in the Case Shiller methodology\n",
    "            periods - array of all periods in the sample\n",
    "    outputs: DataFrame with index of periods and columns `weighted` and `unweighted` for the house price index\n",
    "            first period index value is guaranteed to be 1.0 by convention\n",
    "'''\n",
    "def buildIndex(X, Z, W, periods):\n",
    "    #1) Estimate b by running regression using instrumental variables b = (Z'X)^-1 x X'w\n",
    "    coeff = np.linalg.inv(Z.T.dot(X)).dot(Z.T).dot(W)\n",
    "    idx = 1/(coeff.reshape(X.shape[1]))\n",
    "    unweighted = pd.DataFrame([1,*idx], index=periods, columns=['unweighted'])\n",
    "\n",
    "    #2) Calculate weights for each observation \n",
    "    resid = W - X.dot(coeff)\n",
    "    reg = LinearRegression().fit(deltaT, resid**2)\n",
    "    weights = np.sqrt(reg.predict(deltaT).clip(min=0.00001))\n",
    "    Omega = np.diag(np.reshape(1/weights,X.shape[0]))\n",
    "\n",
    "    #3) Estimate b again incorporating weights b = (Z'OmegaX)^-1 x Z'Omega w\n",
    "    coeff_weighted = np.linalg.inv(Z.T.dot(Omega).dot(X)).dot(Z.T).dot(Omega).dot(W)\n",
    "    idx_weighted = 1/(coeff_weighted.reshape(X.shape[1]))\n",
    "    weighted = pd.DataFrame([1,*idx_weighted],index=periods, columns=['weighted'])\n",
    "\n",
    "    return pd.concat([unweighted, weighted], axis=1), weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for only homes that have sold more than once (not technically required but reduces memory usage), sort by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8FLUpBpsdEM"
   },
   "outputs": [],
   "source": [
    "rpt_sales = df[['period', 'uid', 'sale_price', 'neighborhood', 'sale_date']] \\\n",
    "                .groupby('uid') \\\n",
    "                .filter(lambda x: len(x) >= 2) \\\n",
    "                .sort_values('sale_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build design matrices, and construct the index values. Indices are constructed using the repeat sales methodology, meaning that we only look at homes that have sold several times and track the percentage change in price between the first sale and the next sale, which ideally represents an apples-to-apples comparison. See Case Shiller methodology for full description. Known issues is that if the house was remodeled or otherwise improved, we don't have this information so it wouldn't get incorporated. But homes also on average lose value to depreciation/age, and with thousands of transactions this represents the best price comparison possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, W, Z, deltaT, uid_key, periods = createDesignMatrices(rpt_sales)\n",
    "idx, weights = buildIndex(X, Z, W, periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the weighted house price index along with a 1-year/4-quarter rolling average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "CgW2dNWBBHqG",
    "outputId": "6a659e9c-aa0a-46c4-a152-1656a9df38b8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_idx(result, ax, area_name):\n",
    "    index = result.index.to_timestamp()\n",
    "    ax.set_title(f\"{area_name} House Price Index\")\n",
    "\n",
    "    ax.plot(index, result.weighted.values, \n",
    "                   c='k',\n",
    "                   linestyle=':',\n",
    "                   alpha=.5, label=\"Actual\")\n",
    "\n",
    "    ax.plot(index, result.smoothed.values, label=\"Smoothed\")\n",
    "    \n",
    "    ax.axhline(1.0, c='k', lw=1, alpha=.25)\n",
    "    ax.legend()\n",
    "    \n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_formatter(ticker.StrMethodFormatter(\"{:.0%}\"))\n",
    "    ax.yaxis.tick_right()\n",
    "\n",
    "smoothed = idx.weighted.rolling(4,\n",
    "        win_type='gaussian',\n",
    "        min_periods=1,\n",
    "        center=True).mean(std=2).rename(\"smoothed\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(600/72,400/72))\n",
    "plot_idx(pd.concat([idx, smoothed], axis=1), ax, \"Manhattan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine some of the smaller neighborhoods together and eliminate very tiny neighborhoods. FYI, Javits Center is basically Hudson Yards but sadly only has 119 datapoints. \n",
    "\n",
    "Here are the reasons why certain neighborhoods were combined:\n",
    "* Chinatown and Little Italy both had way too few data transactions on their own - merged together\n",
    "* Javits Center (now known as \"Hudson Yards\") only had 119 datapoints, merged with Clinton\n",
    "* Southbridge is a tiny neighborhood below Tribeca with few transactions, merged with Financial District.\n",
    "* Harlem West and Harlem Upper had too few transactions on their own, merged together\n",
    "* Midtown CBD has very few transactions, merged with Midtown East. Debated Midtown West but I believe this reflects the area around Grand Central more than areas west of 5th Avenue.\n",
    "* Kips Bay and Manhattan Valley were generating very volatile index values. Kips Bay merged with Flatiron (I debated merging with Murray Hill or Gramercy). Manhattan Valley merged with Morningside Heights but could also be merged with UWS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude neighborhoods with very few datapoints\n",
    "FILTERED_NEIGHBORHOODS=['manhattan-unknown', 'roosevelt island']\n",
    "COMBINED_NEIGHBORHOODS = {\n",
    "    'chinatown':                 'chinatown/little italy',\n",
    "    'little italy':              'chinatown/little italy',\n",
    "    'javits center':             'clinton',\n",
    "    'southbridge':               'financial',\n",
    "    'harlem-west':               'harlem-west-upper',\n",
    "    'harlem-upper':              'harlem-west-upper',\n",
    "    'midtown-cbd':               'midtown-east',\n",
    "    'upper east side (96-110)':  'upper east side (79-110)',\n",
    "    'upper east side (79-96)':   'upper east side (79-110)',\n",
    "    'kips bay':                  'flatiron/kips bay',\n",
    "    'flatiron':                  'flatiron/kips bay',\n",
    "    'manhattan valley':          'morningside heights',\n",
    "}\n",
    "filtered = rpt_sales.neighborhood.isin(FILTERED_NEIGHBORHOODS)\n",
    "grouped = rpt_sales[~filtered].replace({\"neighborhood\": COMBINED_NEIGHBORHOODS}).groupby('neighborhood')\n",
    "grouped.size().sort_values().plot.bar(figsize=(15,5), title=\"Number of repeat sales in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Create index values for every neighborhood, along with rolling averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = None\n",
    "for row, (name, group) in enumerate(grouped):\n",
    "    X, W, Z, deltaT, uid_key, periods = createDesignMatrices(group)\n",
    "    try:\n",
    "        idx,weights = buildIndex(X,Z,W, periods)\n",
    "        idx['neighborhood'] = name\n",
    "        \n",
    "        smoothed = idx.weighted.rolling(4,\n",
    "            win_type='gaussian',\n",
    "            min_periods=1,\n",
    "            center=True).mean(std=2).rename(\"smoothed\")\n",
    "        \n",
    "        idx = pd.concat([idx,smoothed], axis=1)\n",
    "        \n",
    "        if results is None:\n",
    "            results = idx\n",
    "        else:\n",
    "            results = pd.concat([results, idx])\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(name, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display graph indices for all neighborhoods, in alphabetical order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "nrows = int(np.ceil(len(results.groupby('neighborhood').groups) / ncols))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, nrows*3), sharey=True)\n",
    "\n",
    "for row, (name, idx) in enumerate(results.groupby('neighborhood')):\n",
    "    plot_idx(idx, axes.flat[row], name)\n",
    "                                  \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate year over year growth for each neighborhood and plot it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = results.set_index('neighborhood',append=True).weighted.unstack('neighborhood').pct_change(4).iloc[-1]\n",
    "mr.sort_values(inplace=True)\n",
    "figsize= (15,2.5)\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "ax.set_title(\"Change in Housing Prices, Q2'2019-Q2'2020\")\n",
    "bars = ax.bar(mr.index, mr, width=.825, capsize=2)\n",
    "    \n",
    "ax.axhline(0.0, linestyle=':', color='k', lw=1)\n",
    "\n",
    "ax.set_xticklabels(mr.index, rotation=90, fontsize=11)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_formatter(ticker.StrMethodFormatter(\"{:.0%}\"))\n",
    "ax.yaxis.tick_right()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NY-condos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
